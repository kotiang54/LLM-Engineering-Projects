{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615ea033",
   "metadata": {},
   "source": [
    "# LLM Question Answering Tool\n",
    "\n",
    "This notebook demonstrates how to build a tool that takes a technical question and generates an explanation using either an OpenAI GPT model or a locally hosted LLaMA model via Ollama. The project illustrates prompt processing, model integration, and streaming output to the notebook interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b3f87",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b70a68",
   "metadata": {},
   "source": [
    "### Define Model Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models as constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4.1-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771416d",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac47d21",
   "metadata": {},
   "source": [
    "### Function to Stream Model Responses\n",
    "This function detects whether to use an OpenAI GPT model or an Ollama LLaMA model and streams the model output directly to the notebook as markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df301b0-5c00-4b82-bc7f-3293e0ce112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_response(model, question):\n",
    "    if \"gpt\" in model.lower():\n",
    "        # Use OpenAI client for GPT models\n",
    "        openai = OpenAI()\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": question}],\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in stream:\n",
    "            response += chunk.choices[0].delta.content or ''\n",
    "            response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "    else:\n",
    "        # For Ollama models, use requests directly\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "        stream = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": model,\n",
    "                \"prompt\": question,\n",
    "                \"stream\": True},\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for line in stream.iter_lines():\n",
    "            if line:\n",
    "                json_line = json.loads(line.decode('utf-8'))\n",
    "                if \"response\" in json_line:\n",
    "                    token = json_line[\"response\"]\n",
    "                    response += token\n",
    "                    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7073cae8-74b5-4356-ad35-6c2fe6128188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Let's break down the code snippet:\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "### What the code does:\n",
       "\n",
       "1. **Set comprehension:**  \n",
       "   python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   \n",
       "   This creates a **set** of authors extracted from the iterable `books`.\n",
       "\n",
       "   - `books` is expected to be an iterable (like a list) of dictionaries (or dictionary-like objects).\n",
       "   - For each `book` in `books`, it calls `book.get(\"author\")`.\n",
       "   - The `if book.get(\"author\")` condition filters out any book where `\"author\"` is missing (returns `None` or something falsy).\n",
       "   - The `.get(\"author\")` ensures that if `\"author\"` is missing, it returns `None` instead of raising an error.\n",
       "   - The result is a set of all unique authors found (because sets automatically eliminate duplicates).\n",
       "\n",
       "2. **`yield from`**:  \n",
       "   The statement:\n",
       "   python\n",
       "   yield from <iterable>\n",
       "   \n",
       "   is used inside a generator function to yield all elements from an iterable one by one.\n",
       "\n",
       "   Here,\n",
       "   python\n",
       "   yield from { ... }\n",
       "   \n",
       "   will yield each unique author in the set to the caller, one at a time.\n",
       "\n",
       "### Why this code is written this way:\n",
       "\n",
       "- **Removing duplicates:**  \n",
       "  Using a set comprehension removes duplicate authors automatically, so each author is yielded only once.\n",
       "\n",
       "- **Filtering missing authors:**  \n",
       "  Using the `if book.get(\"author\")` filters out any books missing the `\"author\"` key or where it is `None` or falsy, so the generator only yields actual author values.\n",
       "\n",
       "- **Use of `yield from`:**  \n",
       "  Instead of looping and doing:\n",
       "  python\n",
       "  for author in { ... }:\n",
       "      yield author\n",
       "  \n",
       "  the code uses `yield from` which is a concise way to yield every element of an iterable.\n",
       "\n",
       "### Summary:\n",
       "\n",
       "This code snippet is part of a generator function that yields **unique, non-empty authors** from a collection of book dictionaries, in no particular order, by:\n",
       "\n",
       "- Gathering all authors into a set to ensure uniqueness and filter out missing values.\n",
       "- Yielding each author one by one via `yield from`.\n",
       "\n",
       "---\n",
       "\n",
       "**Example:**\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book A\", \"author\": \"Alice\"},\n",
       "    {\"title\": \"Book B\", \"author\": \"Bob\"},\n",
       "    {\"title\": \"Book C\", \"author\": \"Alice\"},\n",
       "    {\"title\": \"Book D\"},  # author missing\n",
       "    {\"title\": \"Book E\", \"author\": None}\n",
       "]\n",
       "\n",
       "def get_authors():\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "print(list(get_authors()))\n",
       "# Possible output: ['Alice', 'Bob']  (order not guaranteed due to set)\n",
       "\n",
       "\n",
       "This confirms the purpose and behavior of the original code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4.1-mini to answer, with streaming\n",
    "# Here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "\n",
    "stream_response(MODEL_GPT, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This line of code uses a feature called generator expressions, which is a compact way to create iterators. Let's break it down:\n",
       "\n",
       "1. `yield from`: This keyword is used with generator expressions to \"forward\" the iteration over another iterator.\n",
       "2. `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is an expression that generates values on-the-fly.\n",
       "\n",
       "Here's what happens when this code is executed:\n",
       "\n",
       "- It iterates over each item `book` in the collection of objects `books`.\n",
       "- For each item, it checks if the dictionary inside `book` contains a key called `\"author\"` and has a value (i.e., not an empty string or None).\n",
       "- If the condition is met, it yields the value of the `\"author\"` key within that dictionary.\n",
       "\n",
       "However, there's something more going on here - `yield from` is used with `yield*`. The correct syntax should be:\n",
       "\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "In this corrected version, the expression `(book.get(\"author\")) for book in books if book.get(\"author\")` would itself produce an iterator. However, `yield*` allows you to expand this into a larger iterable.\n",
       "\n",
       "A better and more Pythonic way to write this code would be:\n",
       "\n",
       "```python\n",
       "for author in (book.get(\"author\", None) for book in books if book.get(\"author\")):\n",
       "    yield author\n",
       "```\n",
       "\n",
       "Or using the list comprehension equivalent of generator expressions, as provided by `list` function:\n",
       "\n",
       "```python\n",
       "authors = [book.get(\"author\") for book in books if book.get(\"author\")]\n",
       "for author in authors:\n",
       "    yield author\n",
       "```\n",
       "\n",
       "This version does essentially the same thing but avoids using generators which are more suitable when you need to execute a piece of code once, then continue execution from where it left off. The generator expression is often used with `yield` or `yield*`, and the latter allows you to \"forward\" the iteration over another iterator.\n",
       "\n",
       "The correct usage of `yield from` would be as follows:\n",
       "\n",
       "```python\n",
       "def get_authors():\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "# Usage:\n",
       "for author in get_authors():\n",
       "    print(author)\n",
       "```\n",
       "\n",
       "This version correctly uses the `yield from` expression."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "stream_response(MODEL_LLAMA, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b627f4a-5815-4ea4-a39d-46bfab0f9290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
